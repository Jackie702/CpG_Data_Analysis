{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Ciyuan YU\n",
    "Date: 2020-08-31 22:06:14\n",
    "LastEditTime: 2020-09-23 22:58:33\n",
    "LastEditors: Please set LastEditors\n",
    "Description: Calculate CpG data to find the combination with largest impact on cervical tumor\n",
    "FilePath: /CpG_data_analysis/cpgs_selection_v1.0.py\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from itertools import combinations\n",
    "import copy\n",
    "import argparse\n",
    "\n",
    "# the switch of printing logs\n",
    "test_open = 1\n",
    "\n",
    "class data_container:\n",
    "    def __init__(self, cpg_file = \"./myNorm_0829model.csv\", \n",
    "                 label_file = \"./group.csv\", \n",
    "                 threshold = 0.3, \n",
    "                 subset_num = 4):\n",
    "        self.cpg_path = cpg_file\n",
    "        self.label_path = label_file\n",
    "        self.ig_threshold = threshold\n",
    "        self.subset_size = subset_num\n",
    "        \n",
    "        self.cpg_data = None\n",
    "        self.label_data = None\n",
    "        self.label_s = None\n",
    "        \n",
    "        self.discret_data = None\n",
    "        self.info_gain_list = []\n",
    "        self.filtered_ig_list = []\n",
    "        self.qualified_feature_index = []\n",
    "        self.candidate_feature_dict = {}\n",
    "        self.feature_combs = []\n",
    "\n",
    "        self.feature_qualified = []\n",
    "        \n",
    "    \n",
    "    ##### read in, organize and print data #####\n",
    "    def _read_files(self):\n",
    "        self.cpg_data = pd.read_csv(self.cpg_path)\n",
    "        self.label_data = pd.read_csv(self.label_path)\n",
    "        return\n",
    "        \n",
    "    def _organize_raw_data(self):\n",
    "        # drop the sequential numbers of labels\n",
    "        self.label_data.drop(self.label_data.columns[0], axis=1, inplace=True)\n",
    "        self.label_data.replace(\"Tumor\", 1, inplace=True)\n",
    "        self.label_data.replace(\"Normal\", 0, inplace=True)\n",
    "        self.label_s = pd.Series(self.label_data.iloc[:, 0])       # make label pandas.DataFrame info pandas.Series\n",
    "\n",
    "        # convert the matrix of cpg data\n",
    "        self.cpg_data.set_index(\"Unnamed: 0\", inplace=True)\n",
    "        self.cpg_data = pd.DataFrame(self.cpg_data.values.T, \n",
    "                                    index=self.cpg_data.columns, \n",
    "                                    columns=self.cpg_data.index)\n",
    "        self.cpg_data = self.cpg_data.reset_index(drop = True)      # reset cpg data index from TCGA-XX-XXXX-XX to 0 ~ n\n",
    "        return\n",
    "    \n",
    "    def print_data(self):\n",
    "        print(\"\\n####### cpg data #######\\n\")\n",
    "        print(self.cpg_data)\n",
    "        print(\"\\n####### labels #######\\n\")\n",
    "        print(self.label_data)\n",
    "        print(\"\\n####### Above are raw data we have after organization #######\\n\")\n",
    "        return\n",
    "\n",
    "    def read_and_organize_data(self):\n",
    "        self._read_files()\n",
    "        self._organize_raw_data()\n",
    "        \n",
    "        if test_open:\n",
    "            self.print_data()\n",
    "        return\n",
    "    \n",
    "    def save_transformed_csv(self):\n",
    "        self.cpg_data.to_csv(\"cpg_data_transformed.csv\")\n",
    "        self.label_data.to_csv(\"label_transformed.csv\")\n",
    "        return\n",
    "\n",
    "    # discretize all raw data\n",
    "    def discretize_all(self):\n",
    "        self.discret_data = copy.deepcopy(self.cpg_data)\n",
    "        intervals = [x/10 for x in range(11)]\n",
    "        disc_values = [y for y in range(1, 11)]\n",
    "        for i in range(self.cpg_data.shape[1]):\n",
    "            disc_column = pd.cut(self.cpg_data.iloc[:, i], bins=intervals, labels=disc_values)\n",
    "            self.discret_data.iloc[:, i] = disc_column\n",
    "        return\n",
    "\n",
    "    # calculate a columns of info entropy + conditional entropy\n",
    "    def calc_one_column_info_gain(self, data_column):\n",
    "        p_x_list = self.label_s.value_counts() / self.label_s.shape[0]          # calculate the probility of each label element\n",
    "        p_y_list = data_column.value_counts() / data_column.shape[0]            # calculate the probility of each number element\n",
    "\n",
    "        if test_open:\n",
    "            print(\"#################################################################################################\")\n",
    "            print(\"\\np_x_list:\\n\", p_x_list)\n",
    "            print(\"\\np_y_list:\\n\", p_y_list)\n",
    "\n",
    "        H_x = 0\n",
    "        for i in range(p_y_list.shape[0]):\n",
    "            # print(f\"p_x_list[{i}]={p_x_list[i]}\")\n",
    "            if p_x_list[i] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                H_x += -(p_x_list[i] * math.log(p_x_list[i], 2))\n",
    "\n",
    "        if test_open:\n",
    "            print(\"\\nH_x:\\n\", H_x)\n",
    "\n",
    "        # 问题出在这里！！！！！！！！！！！！  data_column的index是TCGA-XX-XXXX-XX， 需要改为序号\n",
    "        x_label_eql_0 = data_column[self.label_s[data_column.index] == 0]       # get numbers whose label is 0\n",
    "        x_label_eql_1 = data_column[self.label_s[data_column.index] == 1]       # get numbers whose label is 1\n",
    "        \n",
    "        if test_open:\n",
    "            print(f\"x_label_eql_0:\\n {x_label_eql_0}\")\n",
    "            print(f\"x_label_eql_1:\\n {x_label_eql_1}\\n\")\n",
    "        \n",
    "        p_x_y_0 = x_label_eql_0.value_counts() / x_label_eql_0.shape[0]     # calculate p(X|Y=0)\n",
    "        p_x_y_0 = np.array([n for n in p_x_y_0 if n != 0])                  # eliminate 0 elements for logarithm\n",
    "        p_x_y_1 = x_label_eql_1.value_counts() / x_label_eql_1.shape[0]     # calculate p(X|Y=1)\n",
    "        p_x_y_1 = np.array([n for n in p_x_y_1 if n != 0])                  # eliminate 0 elements for logarithm\n",
    "        \n",
    "        if test_open:\n",
    "            print(f\"p_x_y_0:\\n {p_x_y_0}\")\n",
    "            print(f\"p_x_y_1:\\n {p_x_y_1}\\n\")\n",
    "        \n",
    "        H_x_y_eql_0 = - (p_x_y_0 * np.log2(p_x_y_0)).sum()                  # calculate conditional entropy H(X|Y=0)\n",
    "        H_x_y_eql_1 = - (p_x_y_1 * np.log2(p_x_y_1)).sum()                  # calculate conditional entropy H(X|Y=1)\n",
    "        \n",
    "        if test_open:\n",
    "            print(\"\\nH_x_y_eql_0:\", H_x_y_eql_0)\n",
    "            print(\"\\nH_x_y_eql_1:\", H_x_y_eql_1)\n",
    "        \n",
    "        H_x_y = p_y_list[0] * H_x_y_eql_0 + p_y_list[1] * H_x_y_eql_1       # calculate conditon entropy H(X|Y=label)\n",
    "        \n",
    "        if test_open:\n",
    "            print(\"\\nH_x_y:\", H_x_y)\n",
    "            print(\"#################################################################################################\")\n",
    "\n",
    "        return H_x - H_x_y\n",
    "    \n",
    "    # calculate infomation gain column by column, with sequence number in the list\n",
    "    # [(index 0, ig 0), (index 1, ig 1), ..., (index N, ig N)]\n",
    "    def calc_all_info_gain(self):\n",
    "        for i in range(self.discret_data.shape[1]):\n",
    "            ig = self.calc_one_column_info_gain(self.discret_data.iloc[:, i])\n",
    "            self.info_gain_list.append((i, ig))\n",
    "        return \n",
    "\n",
    "    def sort_and_filt(self):\n",
    "        self.info_gain_list.sort(key=lambda x: x[1], reverse=True)  # sort the list in descending order\n",
    "        \n",
    "        # eliminate features whose info gain is less than threshold\n",
    "        for i in range(len(self.info_gain_list)):\n",
    "            if self.info_gain_list[i][1] >= self.ig_threshold:\n",
    "                self.filtered_ig_list.append(self.info_gain_list[i])\n",
    "            else:\n",
    "                break\n",
    "        return\n",
    "    \n",
    "    def create_candidate_feature_dict(self):\n",
    "        for item in self.filtered_ig_list:\n",
    "            self.candidate_feature_dict[item[0]] = item[1]\n",
    "\n",
    "    # get combinations of feature by indices\n",
    "    def get_feature_combs(self):\n",
    "        self.qualified_feature_index = [x[0] for x in self.filtered_ig_list]    # get indices of qualified features\n",
    "        self.feature_combs = combinations(self.qualified_feature_index, self.subset_size)\n",
    "        for i in range():\n",
    "            \n",
    "            for j in range(self.subset_size):\n",
    "                    pass\n",
    "\n",
    "    def cpg_test(self):\n",
    "        self.read_and_organize_data()\n",
    "        self.discretize_all()\n",
    "        self.calc_all_feature_info_gain()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # create a argument parser\n",
    "    arg_parser = argparse.ArgumentParser()\n",
    "    arg_parser.add_argument(\"-c\", \"--cpg\", help=\"the file path of csv file with cpg data\", default=\"./myNorm_0829model.csv\")\n",
    "    arg_parser.add_argument(\"-l\", \"--label\", help=\"the file path of csv file with labels\", default=\"./group.csv\")\n",
    "    arg_parser.add_argument(\"-t\", \"--threshold\", help=\"the threshold for eliminating info gains\", type=int, default=0.3)\n",
    "    arg_parser.add_argument(\"-s\", \"--subset\", help=\"the size of selected cpg subset\", type=int, default=4)\n",
    "    args = arg_parser.parse_args()\n",
    "    \n",
    "    # read and organize data\n",
    "    cpg_data = data_container(args.cpg, args.label, args.threshold, args.subset)\n",
    "    cpg_data.cpg_test()\n",
    "    \n",
    "    \n",
    " "
   ]
  }
 ]
}